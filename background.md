## Intro
Hello, Im Damien Xie. I did my undergraduate in Electrical Engineering in Cincinnati Ohio. After that, I worked as an Electrical Engineer in Ohio for two years. Then decided to pursue my master degree in Ottawa, Canada in Computer Engineering with AI as the focus. After graduation, I landed the AI engineer position in the ETS. I have been working in ETS since then for more than three years. 

During my stay, my job has been mainly focused on the developing and deploying our automated scoring engine - RFS(Rater Feature Services). It is designed to build backend applications for text processing. It is built on top of Apache storm. We use RFS for feature extraction, and there are other engines which leverage the features for scoring purposes. 

In the past three years, I have done modernizations for several legacy services in RFS, including dependency parser, discourse service, grammartical error correction services (including preposition, determiner and spelling errors). All the modernizations involve thorough evaluations using public and private data. 

Apart from that, I also spent lots of time on model deployments by leveraging AWS SageMaker inference. There are two projects involved:
- We have a legacy service in the RFS engine. It performs quite very but uses legacy Python version and deprecated packages. We could not find better alternatives of the service. We have to keep the Python version and packages updated in the RFS version. Therefore, the solution is to create a stand-alone service, and containerize the service, deploy it on AWS Sagemaker. Within the RFS engine, I created a service that validates the input, and send requests to the deployed endpoint. The endpoint has been deployed in both US and Asia region to provide real-time inference. 
- Another project is that we have another RFS-based engine, which contains more than 200 models. There models were trained for different items of data. Each model has a pre-processing config file, which also stays in the engine. The advantage of such setup is that everything is in one place, easy to trace. The major disadvantage is that whenever a request involving to add/edit/delete models, engineers need to do a set of release process. Given more than 200 models, it quickly became a full-time job. I led two engineers on this project. We leveraged the AWS S3 and SageMaker Multi-model inference. All the pre-processing config files and models are stored in a S3 bucket. A Sagemaker multi-model endpoint is deployed and waited for requests come in. On the engine side, I have one service pulls and loads the pre-processing file, and perform pre-processing steps for the input text. After the text is processed, another service sends request along with the processed text to the deployed endpoint. The endpoint then pulls and loads a model from the S3, performs the inference. When it is done, send responses back to the engine. The advantage of such infrastructure is that the application is decoupled from the models. No need to do release process everytime we make the changes to the model. 

Additionally, I have contributed to the RSMTool, an open-source library used to evaluate automated essay scoring models. I implmemented the explainalibity for non-linear models to the library, so that it can be used to give explaination to the non-linear models, like what features give most contributions to the final prediction.  

I have my interests in GEN-Ai as well as model deployments. 